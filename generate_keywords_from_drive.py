import os
import logging
import subprocess
import sys

# üîí –ê–≤—Ç–æ—É—Å—Ç–∞–Ω–æ–≤–∫–∞ PyPDF2 –∏ python-docx, –µ—Å–ª–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
try:
    from PyPDF2 import PdfReader
except ImportError:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "PyPDF2"])
    from PyPDF2 import PdfReader

try:
    from docx import Document
except ImportError:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "python-docx"])
    from docx import Document

from config import PROGRAM_SHEETS, PROGRAM_SHEETS_LIST, OPENAI_API_KEY
from services.google_sheets_service import get_sheet_data, update_keywords_for_discipline
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from openai import OpenAI
import mimetypes
import io
import re

# ID –ø–∞–ø–æ–∫ –Ω–∞ Google –î–∏—Å–∫–µ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º
DRIVE_FOLDER_IDS = {
    "–ú–†–ö": "1QXr2qpizqjcn3O3F8_PHu-_b-5Es8Dds",
    "–¢–ü–†": "1fO3VSIsE4C1B2n2EAlKmOM_g9Qgiqjum",
    "–ë–•": "1HvR5wqnPqupqKtTqG8yOxzBJnMFO0YQY"
}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è Google Drive
SCOPES = ["https://www.googleapis.com/auth/drive.readonly"]
SERVICE_ACCOUNT_FILE = "credentials.json"
creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)
drive_service = build("drive", "v3", credentials=creds)

# OpenAI
client = OpenAI(api_key=OPENAI_API_KEY)

def extract_text_from_docx(file_bytes, file_name):
    file_stream = io.BytesIO(file_bytes)
    doc = Document(file_stream)

    full_text = "\n".join([para.text for para in doc.paragraphs])
    content_blocks = []

    # === –†–ü–î: –ò–∑–≤–ª–µ–∫–∞–µ–º 2-–π —Å—Ç–æ–ª–±–µ—Ü –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü ===
    if file_name.lower().startswith("—Ä–ø–¥"):
        for table in doc.tables:
            for row in table.rows[1:]:
                if len(row.cells) > 1:
                    cell = row.cells[1]
                    text = cell.text.strip()
                    if text:
                        content_blocks.append(text)
        combined_text = "\n".join(content_blocks)

    # === –†–ü–ü ===
    elif file_name.lower().startswith("—Ä–ø–ø"):
        pattern = r"(?<=—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ).*?(?=8\\.|8 |—Ñ–æ—Ä–º—ã –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏|–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏)"
        match = re.search(pattern, full_text, re.IGNORECASE | re.DOTALL)
        combined_text = match.group(0).strip() if match else full_text

    # === –ì–ò–ê ===
    elif file_name.lower().startswith("–≥–∏–∞"):
        pattern = r"(?<=—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –≤–∫—Ä).*?(?=4\\.|–ø–µ—Ä–µ—á–µ–Ω—å —Ç–µ–º|5\\.|–∫—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏)"
        match = re.search(pattern, full_text, re.IGNORECASE | re.DOTALL)
        combined_text = match.group(0).strip() if match else full_text

    else:
        table_text = []
        for table in doc.tables:
            for row in table.rows:
                row_text = [cell.text.strip() for cell in row.cells if cell.text.strip()]
                if row_text:
                    table_text.append(" | ".join(row_text))
        combined_text = full_text + "\n" + "\n".join(table_text)

    return combined_text

def generate_keywords_from_text(text, max_words=200):
    prompt = (
        f"–¢—ã ‚Äî –º–µ—Ç–æ–¥–∏—Å—Ç. –ü—Ä–æ—á–∏—Ç–∞–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã –∏ –≤—ã–¥–µ–ª–∏ {max_words} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é), "
        f"—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É—é—â–∏—Ö –µ—ë —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ. –ù–µ –¥–æ–±–∞–≤–ª—è–π –ø–æ—è—Å–Ω–µ–Ω–∏–π.\n\n{text[:3000]}"
    )

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "–¢—ã ‚Äî –º–µ—Ç–æ–¥–∏—Å—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ —É—á–µ–±–Ω—ã–º –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞–º."},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ OpenAI: {e}")
        return ""

def find_drive_file(folder_id, discipline_name):
    simplified = discipline_name.replace(" ", "_").lower()
    query = f"'{folder_id}' in parents and trashed = false"
    results = drive_service.files().list(q=query, fields="files(id, name)").execute()
    for file in results.get("files", []):
        if simplified in file['name'].lower():
            return file
    return None

def download_file_content(file_id):
    request = drive_service.files().get_media(fileId=file_id)
    file_data = io.BytesIO()
    downloader = MediaIoBaseDownload(file_data, request)
    done = False
    while not done:
        status, done = downloader.next_chunk()
    return file_data.getvalue()

def process_program(program_name, sheet_name):
    logger.info(f"üìò –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–∞–º–º—É: {program_name}")
    folder_id = DRIVE_FOLDER_IDS.get(program_name)
    not_updated = []

    data = get_sheet_data(PROGRAM_SHEETS, f"{sheet_name}!A2:C")
    for i, row in enumerate(data, start=2):
        if len(row) < 2:
            continue
        current_keywords = row[2] if len(row) >= 3 else ""
        if current_keywords.strip():
            logger.info(f"‚è© –ü—Ä–æ–ø—É—Å–∫: –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —É–∂–µ –µ—Å—Ç—å –¥–ª—è {row[1]}")
            continue
        module, discipline = row[0], row[1]
        logger.info(f"üîç {module} ‚Üí {discipline}")

        file = find_drive_file(folder_id, discipline)
        if not file:
            logger.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª –¥–ª—è: {discipline}")
            not_updated.append((module, discipline))
            continue

        content = download_file_content(file['id'])
        filename = file['name'].lower()

        if filename.endswith(".docx"):
            text = extract_text_from_docx(content, filename)
        else:
            logger.warning(f"‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file['name']} (–æ–∂–∏–¥–∞–µ—Ç—Å—è .docx)")
            continue

        if not text.strip():
            not_updated.append((module, discipline))
            continue

        keywords = generate_keywords_from_text(text)
        if keywords:
            update_keywords_for_discipline(module, discipline, keywords)
            logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è {discipline}")
        else:
            not_updated.append((module, discipline))

    if not_updated:
        logger.warning("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è:")
        for m, d in not_updated:
            logger.warning(f"  - {program_name} ‚Üí {m} ‚Üí {d}")
    else:
        logger.info("\n‚úÖ –í—Å–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã!")

if __name__ == "__main__":
    for program, sheet in PROGRAM_SHEETS_LIST.items():
        process_program(program, sheet)