import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import time
import logging
import re
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from services.gpt_service import generate_ai_response
from services.google_sheets_service import update_keywords_for_discipline, get_sheet_data

# === –ù–ê–°–¢–†–û–ô–ö–ê ===
PROGRAM_URLS = {
    "–¢–ü–†": "https://d.mgpu.ru/plan/public/task?id=2390",
    "–ú–†–ö": "https://d.mgpu.ru/plan/public/task?id=2382",
    "–ë–•": "https://d.mgpu.ru/plan/public/task?id=2386",
}

logging.basicConfig(level=logging.DEBUG)

# === SELENIUM –ù–ê–°–¢–†–û–ô–ö–ò ===
def init_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    driver = webdriver.Chrome(options=chrome_options)
    return driver

# === –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò ===
def normalize(text):
    return re.sub(r'\s+', ' ', text.lower().strip())

def extract_text_from_url(url, driver):
    driver.get(url)
    time.sleep(3)
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    for tag in soup(['script', 'style', 'nav', 'footer', 'header']):
        tag.decompose()
    text = soup.get_text(separator=' ')
    text = ' '.join(text.split())
    return text[:7000]

def generate_keywords_from_text(text, discipline, module):
    prompt = (
        f"–¢—ã ‚Äî –º–µ—Ç–æ–¥–∏—Å—Ç. –ü—Ä–æ—á–∏—Ç–∞–π —Ç–µ–∫—Å—Ç —Ä–∞–±–æ—á–µ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã "
        f"¬´{discipline}¬ª –º–æ–¥—É–ª—è ¬´{module}¬ª. –ù–∞ –µ–≥–æ –æ—Å–Ω–æ–≤–µ –≤—ã–¥–µ–ª–∏ 100‚Äì120 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–ª–∏ –ø–æ–Ω—è—Ç–∏–π, "
        f"—Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã—Ö –¥–ª—è —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã. –¢–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ –∏ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏—è, –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π."
    )
    return generate_ai_response(prompt + "\n\n" + text)

def extract_discipline_links(page_url, driver):
    driver.get(page_url)
    time.sleep(2)

    # –†–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –≤—Å–µ –º–æ–¥—É–ª–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
    toggles = driver.find_elements(By.CLASS_NAME, "accordion-toggle")
    logging.debug(f"–ù–∞–π–¥–µ–Ω–æ {len(toggles)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ .accordion-toggle")
    for t in toggles:
        logging.debug(f"  ‚û§ –¢–µ–∫—Å—Ç: {t.text}")

    for toggle in toggles:
        try:
            ActionChains(driver).move_to_element(toggle).click(toggle).perform()
            time.sleep(0.5)
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∏–∫–Ω—É—Ç—å –ø–æ –º–æ–¥—É–ª—é: {e}")

    time.sleep(2)
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    disciplines = []

    for block in soup.select(".panel-collapse"):
        module_header = block.find_previous("div", class_="panel-heading")
        module_name = module_header.get_text(strip=True) if module_header else "–ú–æ–¥—É–ª—å"

        for row in block.select("table.table tbody tr"):
            cells = row.find_all("td")
            if not cells:
                continue

            discipline_cell = cells[0]
            link = discipline_cell.find("a")
            if link and "rpd" in link.get("href"):
                href = link.get("href")
                discipline_name = link.get_text(strip=True)
                full_url = "https://d.mgpu.ru" + href if href.startswith("/") else href

                disciplines.append({
                    "module": module_name,
                    "discipline": discipline_name,
                    "url": full_url
                })
                logging.info(f"–ù–∞–π–¥–µ–Ω–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞: {module_name} ‚Üí {discipline_name} ‚Üí {full_url}")

    return disciplines

def process_program(program_name, page_url, sheet_name, driver):
    from config import PROGRAM_SHEETS
    logging.info(f"üìò –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–∞–º–º—É: {program_name}")
    disciplines = extract_discipline_links(page_url, driver)
    logging.debug(f"–ù–∞–π–¥–µ–Ω–æ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω: {len(disciplines)}")
    for item in disciplines:
        logging.debug(f"  - {item['module']} ‚Üí {item['discipline']} ‚Üí {item['url']}")

    sheet_data = get_sheet_data(PROGRAM_SHEETS, f"{sheet_name}!A2:C")

    not_updated = []

    for item in disciplines:
        module = normalize(item["module"])
        discipline = normalize(item["discipline"])
        url = item["url"]

        found = False
        for row in sheet_data:
            if len(row) >= 2:
                sheet_module = normalize(row[0])
                sheet_discipline = normalize(row[1])
                logging.debug(f"‚Üí –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: '{sheet_module}' == '{module}', '{sheet_discipline}' == '{discipline}'")

                if sheet_module == module and sheet_discipline == discipline:
                    found = True
                    try:
                        logging.info(f"üîç {item['module']} ‚Üí {item['discipline']}")
                        text = extract_text_from_url(url, driver)
                        keywords = generate_keywords_from_text(text, item['discipline'], item['module'])
                        logging.debug(f"[GPT] –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keywords[:300]}...")
                        update_keywords_for_discipline(item['module'], item['discipline'], keywords)
                        logging.info("‚úÖ –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
                    except Exception as e:
                        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏: {item['module']} ‚Üí {item['discipline']}: {e}")
                        not_updated.append(f"{program_name} ‚Üí {item['module']} ‚Üí {item['discipline']}")
                    break

        if not found:
            logging.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ: {item['module']} ‚Üí {item['discipline']}")
            not_updated.append(f"{program_name} ‚Üí {item['module']} ‚Üí {item['discipline']}")

    if not_updated:
        logging.info("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –¥–∏—Å—Ü–∏–ø–ª–∏–Ω:")
        for item in not_updated:
            logging.info(f"- {item}")
    else:
        logging.info("\n‚úÖ –í—Å–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã!")

# === –ó–ê–ü–£–°–ö ===
if __name__ == "__main__":
    from config import PROGRAM_SHEETS_LIST
    driver = init_driver()

    try:
        for program, url in PROGRAM_URLS.items():
            sheet_name = PROGRAM_SHEETS_LIST.get(program)
            if sheet_name:
                process_program(program, url, sheet_name, driver)
            else:
                logging.warning(f"‚ö†Ô∏è –ù–µ—Ç –ª–∏—Å—Ç–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º—ã: {program}")
    finally:
        driver.quit()